{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicativo para Detecção de Deepfakes - Streamlit"
      ],
      "metadata": {
        "id": "iNFsPzXVO-a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste notebook, para ser possível fazer as detecções, é necessário que na aba 'Ambiente de execução', 'Alterar o tipo de ambinete de execução', esteja selecionado o modo com alguma GPU."
      ],
      "metadata": {
        "id": "EdORCTWreYd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Para ter acesso a alguns exemplos para testar o APP, clone o repositório a seguir e use as imagens e vídeos da pasta 'samples'**"
      ],
      "metadata": {
        "id": "0uzYiCe2d5JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonar o repositório do projeto TCC\n",
        "!git clone https://github.com/NathFarinha/TCC_DeepFake_Detection_v1.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW34ipK1FmfI",
        "outputId": "eaea08be-484d-4f37-ef3c-89dee9dcd492"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TCC_DeepFake_Detection_v1'...\n",
            "remote: Enumerating objects: 375, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 375 (delta 45), reused 144 (delta 21), pack-reused 196\u001b[K\n",
            "Receiving objects: 100% (375/375), 98.14 MiB | 39.36 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Organizando ambiente para execução do APP**"
      ],
      "metadata": {
        "id": "kXnMXNyveLC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "id": "qs1zT2OLPAtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfc9a9d-806e-4bab-ac58-0e2222e53fb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonar o repositório do projeto do artigo 'Video Face Manipulation Detection Through Ensemble of CNNs'\n",
        "!git clone https://github.com/polimi-ispl/icpr2020dfdc\n",
        "!pip install efficientnet-pytorch\n",
        "!pip install -U git+https://github.com/albu/albumentations > /dev/null\n",
        "%cd icpr2020dfdc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKjLp5GzFmco",
        "outputId": "ca3d37a3-f0ff-4967-9aaf-34091998d581"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'icpr2020dfdc'...\n",
            "remote: Enumerating objects: 645, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 645 (delta 96), reused 80 (delta 80), pack-reused 537\u001b[K\n",
            "Receiving objects: 100% (645/645), 99.63 MiB | 26.09 MiB/s, done.\n",
            "Resolving deltas: 100% (336/336), done.\n",
            "Collecting efficientnet-pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=10ee9645fd4667a8769c7e4fa85e79ab26c8ceccbda2e233433d35793046a608\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/albu/albumentations /tmp/pip-req-build-stqm8o10\n",
            "/content/icpr2020dfdc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Criando o APP Streamlit**"
      ],
      "metadata": {
        "id": "le66uwSHPE8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import torch\n",
        "from torch.utils.model_zoo import load_url\n",
        "from scipy.special import expit\n",
        "from PIL import Image\n",
        "import streamlit as st\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "from blazeface import FaceExtractor, BlazeFace, VideoReader\n",
        "from architectures import fornet, weights\n",
        "from isplutils import utils\n",
        "\n",
        "# Configuração do dispositivo\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "face_policy = 'scale'\n",
        "face_size = 224\n",
        "frames_per_video = 32\n",
        "\n",
        "# Inicialize o modelo de detecção facial BlazeFace\n",
        "facedet = BlazeFace().to(device)\n",
        "facedet.load_weights(\"blazeface/blazeface.pth\")\n",
        "facedet.load_anchors(\"blazeface/anchors.npy\")\n",
        "videoreader = VideoReader(verbose=False)\n",
        "video_read_fn = lambda x: videoreader.read_frames(x, num_frames=frames_per_video)\n",
        "face_extractor = FaceExtractor(video_read_fn=video_read_fn, facedet=facedet)\n",
        "\n",
        "# Função para realizar a detecção de deep fakes com base no modelo selecionado\n",
        "def detect_deep_fake(uploaded_file, selected_model, selected_dataset):\n",
        "    # Crie um diretório temporário para salvar o arquivo\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "    # Salve o arquivo temporariamente no diretório temporário\n",
        "    temp_file_path = os.path.join(temp_dir, uploaded_file.name)\n",
        "    with open(temp_file_path, 'wb') as temp_file:\n",
        "        temp_file.write(uploaded_file.read())\n",
        "\n",
        "    if uploaded_file.type.startswith('image'):\n",
        "        im = Image.open(temp_file_path)\n",
        "        im_faces = face_extractor.process_image(img=im)\n",
        "        im_face = im_faces['faces'][0] if len(im_faces['faces']) > 0 else None\n",
        "\n",
        "        model_url = weights.weight_url['{:s}_{:s}'.format(selected_model, selected_dataset)]\n",
        "        net = getattr(fornet, selected_model)().eval().to(device)\n",
        "        net.load_state_dict(load_url(model_url, map_location=device, check_hash=True))\n",
        "        transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)\n",
        "\n",
        "        if im_face is not None:\n",
        "            faces_t = torch.stack([transf(image=im_face)['image']])\n",
        "\n",
        "            with torch.no_grad():\n",
        "                faces_pred = torch.sigmoid(net(faces_t.to(device))).cpu().numpy().flatten()\n",
        "\n",
        "            avg_score = expit(faces_pred.mean())\n",
        "            prediction = 'FAKE' if avg_score >= 0.6 else 'REAL'\n",
        "        else:\n",
        "            return 'Não foi possível detectar uma face na imagem.'\n",
        "\n",
        "    elif uploaded_file.type.startswith('video'):\n",
        "        model_url = weights.weight_url['{:s}_{:s}'.format(selected_model, selected_dataset)]\n",
        "        net = getattr(fornet, selected_model)().eval().to(device)\n",
        "        net.load_state_dict(load_url(model_url, map_location=device, check_hash=True))\n",
        "        transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)\n",
        "\n",
        "        vid_faces = face_extractor.process_video(temp_file_path)\n",
        "        faces_t = torch.stack([transf(image=frame['faces'][0])['image'] for frame in vid_faces if len(frame['faces'])])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            faces_pred = net(faces_t.to(device)).cpu().numpy().flatten()\n",
        "\n",
        "        avg_score = expit(faces_pred.mean())\n",
        "        prediction = 'FAKE' if avg_score >= 0.6 else 'REAL'\n",
        "\n",
        "    else:\n",
        "        return 'Tipo de arquivo não suportado.'\n",
        "\n",
        "    return prediction, avg_score\n",
        "\n",
        "# Configuração de estilo do Streamlit\n",
        "st.set_page_config(\n",
        "    page_title=\"Detecção de Deep Fakes\",\n",
        "    page_icon=\"✅\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Página de detecção de Deep Fakes\n",
        "page = st.sidebar.radio(\"Selecione uma página\", [\"Detecção de Deep Fakes\", \"Informações da Autora\"])\n",
        "\n",
        "if page == \"Detecção de Deep Fakes\":\n",
        "    # Cabeçalho do aplicativo Streamlit\n",
        "    st.title('Detecção de Deep Fakes')\n",
        "\n",
        "    # Upload de arquivo de imagem ou vídeo\n",
        "    uploaded_file = st.file_uploader('Envie uma imagem ou vídeo', type=['jpg', 'jpeg', 'png', 'mp4'])\n",
        "\n",
        "    if uploaded_file:\n",
        "        selected_model = st.selectbox('Selecione o modelo', ['EfficientNetB4', 'EfficientNetB4ST','EfficientNetAutoAttB4','EfficientNetAutoAttB4ST'])  # Substitua pelos modelos disponíveis\n",
        "        selected_dataset = st.selectbox('Selecione o conjunto de dados', ['DFDC', 'FFPP'])  # Substitua pelos conjuntos de dados disponíveis\n",
        "\n",
        "        if st.button('Detecção'):\n",
        "            prediction, avg_score = detect_deep_fake(uploaded_file, selected_model, selected_dataset)\n",
        "\n",
        "            if uploaded_file.type.startswith('image'):\n",
        "                st.image(uploaded_file, caption='Imagem enviada', width=500)\n",
        "            elif uploaded_file.type.startswith('video'):\n",
        "                st.video(uploaded_file, format='video/mp4')\n",
        "\n",
        "            st.subheader(prediction)\n",
        "            avg_score = \"{:.4f}\".format(avg_score)\n",
        "            st.write(f'Pontuação média: {avg_score}')\n",
        "\n",
        "\n",
        "elif page == \"Informações da Autora\":\n",
        "    st.title('Informações da Autora')\n",
        "    st.markdown(\"### Nome:\")\n",
        "    st.write(\"Nathalia Farinha Rodrigues\")\n",
        "    st.markdown(\"### TCC:\")\n",
        "    st.write(\"ANÁLISE DE MODELOS DETECTORES DE DEEPFAKE USANDO APRENDIZADO PROFUNDO\")\n",
        "    st.markdown(\"### Curso:\")\n",
        "    st.write(\"Engenharia Elétrica\")\n",
        "    st.markdown(\"### Orientador:\")\n",
        "    st.write(\"Prof. Dr. Frank Herman Behrens\")\n",
        "    st.markdown(\"### Coorientador:\")\n",
        "    st.write(\"Prof. Dr. Ademar Takeo Akabane\")\n",
        "    st.markdown(\"### Ano:\")\n",
        "    st.write(\"Campinas 2023\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgrOvbrzPAv0",
        "outputId": "4c5fc458-8014-46b3-d9c2-a6d729648195"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Execute os próximos passos para acessar o link do APP no streamlit**"
      ],
      "metadata": {
        "id": "B1YnDpUbdhv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -la # verifica arquivos\n",
        "! cat app.py # visualizar conteudo do arquivo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-iCubcqFIo4",
        "outputId": "0c82bfd7-3890-439a-9b61-4d4d6301ff28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 188\n",
            "drwxr-xr-x 10 root root  4096 Oct  1 15:49 .\n",
            "drwxr-xr-x  1 root root  4096 Oct  1 15:48 ..\n",
            "-rw-r--r--  1 root root  5210 Oct  1 15:49 app.py\n",
            "drwxr-xr-x  3 root root  4096 Oct  1 15:49 architectures\n",
            "drwxr-xr-x  2 root root  4096 Oct  1 15:49 assets\n",
            "drwxr-xr-x  2 root root  4096 Oct  1 15:49 blazeface\n",
            "-rw-r--r--  1 root root   357 Oct  1 15:49 environment.yml\n",
            "-rw-r--r--  1 root root 16943 Oct  1 15:49 extract_faces.py\n",
            "drwxr-xr-x  8 root root  4096 Oct  1 15:49 .git\n",
            "-rw-r--r--  1 root root    50 Oct  1 15:49 .gitignore\n",
            "-rw-r--r--  1 root root  3271 Oct  1 15:49 index_celebdf.py\n",
            "-rw-r--r--  1 root root  3323 Oct  1 15:49 index_dfdc.py\n",
            "-rw-r--r--  1 root root  3724 Oct  1 15:49 index_ffpp.py\n",
            "drwxr-xr-x  2 root root  4096 Oct  1 15:49 isplutils\n",
            "-rw-r--r--  1 root root 35149 Oct  1 15:49 LICENSE\n",
            "drwxr-xr-x  4 root root  4096 Oct  1 15:49 notebook\n",
            "-rw-r--r--  1 root root  7761 Oct  1 15:49 README.md\n",
            "drwxr-xr-x  2 root root  4096 Oct  1 15:49 scripts\n",
            "drwxr-xr-x  3 root root  4096 Oct  1 15:49 test\n",
            "-rw-r--r--  1 root root 11743 Oct  1 15:49 test_model.py\n",
            "-rw-r--r--  1 root root 19203 Oct  1 15:49 train_binclass.py\n",
            "-rw-r--r--  1 root root 19571 Oct  1 15:49 train_triplet.py\n",
            "-rw-r--r--  1 root root   429 Oct  1 15:49 .travis.yml\n",
            "import torch\n",
            "from torch.utils.model_zoo import load_url\n",
            "from scipy.special import expit\n",
            "from PIL import Image\n",
            "import streamlit as st\n",
            "import os\n",
            "import tempfile\n",
            "\n",
            "from blazeface import FaceExtractor, BlazeFace, VideoReader\n",
            "from architectures import fornet, weights\n",
            "from isplutils import utils\n",
            "\n",
            "# Configuração do dispositivo\n",
            "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
            "face_policy = 'scale'\n",
            "face_size = 224\n",
            "frames_per_video = 32\n",
            "\n",
            "# Inicialize o modelo de detecção facial BlazeFace\n",
            "facedet = BlazeFace().to(device)\n",
            "facedet.load_weights(\"blazeface/blazeface.pth\")\n",
            "facedet.load_anchors(\"blazeface/anchors.npy\")\n",
            "videoreader = VideoReader(verbose=False)\n",
            "video_read_fn = lambda x: videoreader.read_frames(x, num_frames=frames_per_video)\n",
            "face_extractor = FaceExtractor(video_read_fn=video_read_fn, facedet=facedet)\n",
            "\n",
            "# Função para realizar a detecção de deep fakes com base no modelo selecionado\n",
            "def detect_deep_fake(uploaded_file, selected_model, selected_dataset):\n",
            "    # Crie um diretório temporário para salvar o arquivo\n",
            "    temp_dir = tempfile.mkdtemp()\n",
            "\n",
            "    # Salve o arquivo temporariamente no diretório temporário\n",
            "    temp_file_path = os.path.join(temp_dir, uploaded_file.name)\n",
            "    with open(temp_file_path, 'wb') as temp_file:\n",
            "        temp_file.write(uploaded_file.read())\n",
            "\n",
            "    if uploaded_file.type.startswith('image'):\n",
            "        im = Image.open(temp_file_path)\n",
            "        im_faces = face_extractor.process_image(img=im)\n",
            "        im_face = im_faces['faces'][0] if len(im_faces['faces']) > 0 else None\n",
            "\n",
            "        model_url = weights.weight_url['{:s}_{:s}'.format(selected_model, selected_dataset)]\n",
            "        net = getattr(fornet, selected_model)().eval().to(device)\n",
            "        net.load_state_dict(load_url(model_url, map_location=device, check_hash=True))\n",
            "        transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)\n",
            "\n",
            "        if im_face is not None:\n",
            "            faces_t = torch.stack([transf(image=im_face)['image']])\n",
            "\n",
            "            with torch.no_grad():\n",
            "                faces_pred = torch.sigmoid(net(faces_t.to(device))).cpu().numpy().flatten()\n",
            "\n",
            "            avg_score = expit(faces_pred.mean())\n",
            "            prediction = 'FAKE' if avg_score >= 0.6 else 'REAL'\n",
            "        else:\n",
            "            return 'Não foi possível detectar uma face na imagem.'\n",
            "\n",
            "    elif uploaded_file.type.startswith('video'):\n",
            "        model_url = weights.weight_url['{:s}_{:s}'.format(selected_model, selected_dataset)]\n",
            "        net = getattr(fornet, selected_model)().eval().to(device)\n",
            "        net.load_state_dict(load_url(model_url, map_location=device, check_hash=True))\n",
            "        transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)\n",
            "\n",
            "        vid_faces = face_extractor.process_video(temp_file_path)\n",
            "        faces_t = torch.stack([transf(image=frame['faces'][0])['image'] for frame in vid_faces if len(frame['faces'])])\n",
            "\n",
            "        with torch.no_grad():\n",
            "            faces_pred = net(faces_t.to(device)).cpu().numpy().flatten()\n",
            "\n",
            "        avg_score = expit(faces_pred.mean())\n",
            "        prediction = 'FAKE' if avg_score >= 0.6 else 'REAL'\n",
            "\n",
            "    else:\n",
            "        return 'Tipo de arquivo não suportado.'\n",
            "\n",
            "    return prediction, avg_score\n",
            "\n",
            "# Configuração de estilo do Streamlit\n",
            "st.set_page_config(\n",
            "    page_title=\"Detecção de Deep Fakes\",\n",
            "    page_icon=\"✅\",\n",
            "    layout=\"wide\"\n",
            ")\n",
            "\n",
            "# Página de detecção de Deep Fakes\n",
            "page = st.sidebar.radio(\"Selecione uma página\", [\"Detecção de Deep Fakes\", \"Informações da Autora\"])\n",
            "\n",
            "if page == \"Detecção de Deep Fakes\":\n",
            "    # Cabeçalho do aplicativo Streamlit\n",
            "    st.title('Detecção de Deep Fakes')\n",
            "\n",
            "    # Upload de arquivo de imagem ou vídeo\n",
            "    uploaded_file = st.file_uploader('Envie uma imagem ou vídeo', type=['jpg', 'jpeg', 'png', 'mp4'])\n",
            "\n",
            "    if uploaded_file:\n",
            "        selected_model = st.selectbox('Selecione o modelo', ['EfficientNetB4', 'EfficientNetB4ST','EfficientNetAutoAttB4','EfficientNetAutoAttB4ST'])  # Substitua pelos modelos disponíveis\n",
            "        selected_dataset = st.selectbox('Selecione o conjunto de dados', ['DFDC', 'FFPP'])  # Substitua pelos conjuntos de dados disponíveis\n",
            "\n",
            "        if st.button('Detecção'):\n",
            "            prediction, avg_score = detect_deep_fake(uploaded_file, selected_model, selected_dataset)\n",
            "\n",
            "            if uploaded_file.type.startswith('image'):\n",
            "                st.image(uploaded_file, caption='Imagem enviada', width=500)\n",
            "            elif uploaded_file.type.startswith('video'):\n",
            "                st.video(uploaded_file, format='video/mp4')\n",
            "\n",
            "            st.subheader(prediction)\n",
            "            avg_score = \"{:.4f}\".format(avg_score)\n",
            "            st.write(f'Pontuação média: {avg_score}')\n",
            "\n",
            "\n",
            "elif page == \"Informações da Autora\":\n",
            "    st.title('Informações da Autora')\n",
            "    st.markdown(\"### Nome:\")\n",
            "    st.write(\"Nathalia Farinha Rodrigues\")\n",
            "    st.markdown(\"### TCC:\")\n",
            "    st.write(\"ANÁLISE DE MODELOS DETECTORES DE DEEPFAKE USANDO APRENDIZADO PROFUNDO\")\n",
            "    st.markdown(\"### Curso:\")\n",
            "    st.write(\"Engenharia Elétrica\")\n",
            "    st.markdown(\"### Orientador:\")\n",
            "    st.write(\"Prof. Dr. Frank Herman Behrens\")\n",
            "    st.markdown(\"### Coorientador:\")\n",
            "    st.write(\"Prof. Dr. Ademar Takeo Akabane\")\n",
            "    st.markdown(\"### Ano:\")\n",
            "    st.write(\"Campinas 2023\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyW9FzkSFIjj",
        "outputId": "3019bc01-4b01-4468-f827-56688a714945"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/icpr2020dfdc/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/icpr2020dfdc/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m icpr2020dfdc No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m icpr2020dfdc No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m icpr2020dfdc No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m icpr2020dfdc No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 1.758s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "3DqyRNaGFIhD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**O número do IP a seguir será necessário para colar no campo correspondente para acessar o APP**"
      ],
      "metadata": {
        "id": "i3V7qGPUdo7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--cvVgvLFIex",
        "outputId": "b0ae5f8c-8c11-4b16-c1db-ed4cfb0767a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.182.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cole o IP no espaço 'Endpoint IP', e clique em 'Click to Submit'**"
      ],
      "metadata": {
        "id": "rVBzLCr1d1Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YooSjt2HFIcg",
        "outputId": "4eab21e5-a4e0-4019-8464-d2b144ef17c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.685s\n",
            "your url is: https://tiny-monkeys-vanish.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C96KUvXIFIVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-HtnhFtOdDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gNkvRjciu2Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bWbASjaOdAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxtjOBWgFISZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}